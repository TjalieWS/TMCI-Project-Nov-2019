{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The code in this file has mostly not been run, since running it again would take too long. See the individual code files on github for that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "967\n",
      "966\n",
      "965\n",
      "964\n",
      "963\n",
      "962\n",
      "961\n",
      "960\n",
      "959\n",
      "958\n",
      "957\n",
      "956\n",
      "955\n",
      "954\n",
      "953\n",
      "952\n",
      "951\n",
      "950\n",
      "949\n",
      "948\n",
      "947\n",
      "946\n",
      "945\n",
      "944\n",
      "943\n",
      "942\n",
      "941\n",
      "940\n",
      "939\n",
      "938\n",
      "937\n",
      "936\n",
      "935\n",
      "934\n",
      "933\n",
      "932\n",
      "931\n",
      "930\n",
      "929\n",
      "928\n",
      "927\n",
      "926\n",
      "925\n",
      "924\n",
      "923\n",
      "922\n",
      "921\n",
      "920\n",
      "919\n",
      "918\n",
      "917\n",
      "916\n",
      "915\n",
      "914\n",
      "913\n",
      "912\n",
      "911\n",
      "910\n",
      "909\n",
      "908\n",
      "907\n",
      "906\n",
      "905\n",
      "904\n",
      "903\n",
      "902\n",
      "901\n",
      "900\n",
      "899\n",
      "898\n",
      "897\n",
      "896\n",
      "895\n",
      "894\n",
      "893\n",
      "892\n",
      "891\n",
      "890\n",
      "889\n",
      "888\n",
      "887\n",
      "886\n",
      "885\n",
      "884\n",
      "883\n",
      "882\n",
      "881\n",
      "880\n",
      "879\n",
      "878\n",
      "877\n",
      "876\n",
      "875\n",
      "874\n",
      "873\n",
      "872\n",
      "871\n",
      "870\n",
      "869\n",
      "868\n",
      "867\n",
      "866\n",
      "865\n",
      "864\n",
      "863\n",
      "862\n",
      "861\n",
      "860\n",
      "859\n",
      "858\n",
      "857\n",
      "856\n",
      "855\n",
      "854\n",
      "853\n",
      "852\n",
      "851\n",
      "850\n",
      "849\n",
      "848\n",
      "847\n",
      "846\n",
      "845\n",
      "844\n",
      "843\n",
      "842\n",
      "841\n",
      "840\n",
      "839\n",
      "838\n",
      "837\n",
      "836\n",
      "835\n",
      "834\n",
      "833\n",
      "832\n",
      "831\n",
      "830\n",
      "829\n",
      "828\n",
      "827\n",
      "826\n",
      "825\n",
      "824\n",
      "823\n",
      "822\n",
      "821\n",
      "820\n",
      "819\n",
      "818\n",
      "817\n",
      "816\n",
      "815\n",
      "814\n",
      "813\n",
      "812\n",
      "811\n",
      "810\n",
      "809\n",
      "808\n",
      "807\n",
      "806\n",
      "805\n",
      "804\n",
      "803\n",
      "802\n",
      "801\n",
      "800\n",
      "799\n",
      "798\n",
      "797\n",
      "796\n",
      "795\n",
      "794\n",
      "793\n",
      "792\n",
      "791\n",
      "790\n",
      "789\n",
      "788\n",
      "787\n",
      "786\n",
      "785\n",
      "784\n",
      "783\n",
      "782\n",
      "781\n",
      "780\n",
      "779\n",
      "778\n",
      "777\n",
      "776\n",
      "775\n",
      "774\n",
      "773\n",
      "772\n",
      "771\n",
      "770\n",
      "769\n",
      "768\n",
      "767\n",
      "766\n",
      "765\n",
      "764\n",
      "763\n",
      "762\n",
      "761\n",
      "760\n",
      "759\n",
      "758\n",
      "757\n",
      "756\n",
      "755\n",
      "754\n",
      "753\n",
      "752\n",
      "751\n",
      "750\n",
      "749\n",
      "748\n",
      "747\n",
      "746\n",
      "745\n",
      "744\n",
      "743\n",
      "742\n",
      "741\n",
      "740\n",
      "739\n",
      "738\n",
      "737\n",
      "736\n",
      "735\n",
      "734\n",
      "733\n",
      "732\n",
      "731\n",
      "730\n",
      "729\n",
      "728\n",
      "727\n",
      "726\n",
      "725\n",
      "724\n",
      "723\n",
      "722\n",
      "721\n",
      "720\n",
      "719\n",
      "718\n",
      "717\n",
      "716\n",
      "715\n",
      "714\n",
      "713\n",
      "712\n",
      "711\n",
      "710\n",
      "709\n",
      "708\n",
      "707\n",
      "706\n",
      "705\n",
      "704\n",
      "703\n",
      "702\n",
      "701\n",
      "700\n",
      "699\n",
      "698\n",
      "697\n",
      "696\n",
      "695\n",
      "694\n",
      "693\n",
      "692\n",
      "691\n",
      "690\n",
      "689\n",
      "688\n",
      "687\n",
      "686\n",
      "685\n",
      "684\n",
      "683\n",
      "682\n",
      "681\n",
      "680\n",
      "679\n",
      "678\n",
      "677\n",
      "676\n",
      "675\n",
      "674\n",
      "673\n",
      "672\n",
      "671\n",
      "670\n",
      "669\n",
      "668\n",
      "667\n",
      "666\n",
      "665\n",
      "664\n",
      "663\n",
      "662\n",
      "661\n",
      "660\n",
      "659\n",
      "658\n",
      "657\n",
      "656\n",
      "655\n",
      "654\n",
      "653\n",
      "652\n",
      "651\n",
      "650\n",
      "649\n",
      "648\n",
      "647\n",
      "646\n",
      "645\n",
      "644\n",
      "643\n",
      "642\n",
      "641\n",
      "640\n",
      "639\n",
      "638\n",
      "637\n",
      "636\n",
      "635\n",
      "634\n",
      "633\n",
      "632\n",
      "631\n",
      "630\n",
      "629\n",
      "628\n",
      "627\n",
      "626\n",
      "625\n",
      "624\n",
      "623\n",
      "622\n",
      "621\n",
      "620\n",
      "619\n",
      "618\n",
      "617\n",
      "616\n",
      "615\n",
      "614\n",
      "613\n",
      "612\n",
      "611\n",
      "610\n",
      "609\n",
      "608\n",
      "607\n",
      "606\n",
      "605\n",
      "604\n",
      "603\n",
      "602\n",
      "601\n",
      "600\n",
      "599\n",
      "598\n",
      "597\n",
      "596\n",
      "595\n",
      "594\n",
      "593\n",
      "592\n",
      "591\n",
      "590\n",
      "589\n",
      "588\n",
      "587\n",
      "586\n",
      "585\n",
      "584\n",
      "583\n",
      "582\n",
      "581\n",
      "580\n",
      "579\n",
      "578\n",
      "577\n",
      "576\n",
      "575\n",
      "574\n",
      "573\n",
      "572\n",
      "571\n",
      "570\n",
      "569\n",
      "568\n",
      "567\n",
      "566\n",
      "565\n",
      "564\n",
      "563\n",
      "562\n",
      "561\n",
      "560\n",
      "559\n",
      "558\n",
      "557\n",
      "556\n",
      "555\n",
      "554\n",
      "553\n",
      "552\n",
      "551\n",
      "550\n",
      "549\n",
      "548\n",
      "547\n",
      "546\n",
      "545\n",
      "544\n",
      "543\n",
      "542\n",
      "541\n",
      "540\n",
      "539\n",
      "538\n",
      "537\n",
      "536\n",
      "535\n",
      "534\n",
      "533\n",
      "532\n",
      "531\n",
      "530\n",
      "529\n",
      "528\n",
      "527\n",
      "526\n",
      "525\n",
      "524\n",
      "523\n",
      "522\n",
      "521\n",
      "520\n",
      "519\n",
      "518\n",
      "517\n",
      "516\n",
      "515\n",
      "514\n",
      "513\n",
      "512\n",
      "511\n",
      "510\n",
      "509\n",
      "508\n",
      "507\n",
      "506\n",
      "505\n",
      "504\n",
      "503\n",
      "502\n",
      "501\n",
      "500\n",
      "499\n",
      "498\n",
      "497\n",
      "496\n",
      "495\n",
      "494\n",
      "493\n",
      "492\n",
      "491\n",
      "490\n",
      "489\n",
      "488\n",
      "487\n",
      "486\n",
      "485\n",
      "484\n",
      "483\n",
      "482\n",
      "481\n",
      "480\n",
      "479\n",
      "478\n",
      "477\n",
      "476\n",
      "475\n",
      "474\n",
      "473\n",
      "472\n",
      "471\n",
      "470\n",
      "469\n",
      "468\n",
      "467\n",
      "466\n",
      "465\n",
      "464\n",
      "463\n",
      "462\n",
      "461\n",
      "460\n",
      "459\n",
      "458\n",
      "457\n",
      "456\n",
      "455\n",
      "454\n",
      "453\n",
      "452\n",
      "451\n",
      "450\n",
      "449\n",
      "448\n",
      "447\n",
      "446\n",
      "445\n",
      "444\n",
      "443\n",
      "442\n",
      "441\n",
      "440\n",
      "439\n",
      "438\n",
      "437\n",
      "436\n",
      "435\n",
      "434\n",
      "433\n",
      "432\n",
      "431\n",
      "430\n",
      "429\n",
      "428\n",
      "427\n",
      "426\n",
      "425\n",
      "424\n",
      "423\n",
      "422\n",
      "421\n",
      "420\n",
      "419\n",
      "418\n",
      "417\n",
      "416\n",
      "415\n",
      "414\n",
      "413\n",
      "412\n",
      "411\n",
      "410\n",
      "409\n",
      "408\n",
      "407\n",
      "406\n",
      "405\n",
      "404\n",
      "403\n",
      "402\n",
      "401\n",
      "400\n",
      "399\n",
      "398\n",
      "397\n",
      "396\n",
      "395\n",
      "394\n",
      "393\n",
      "392\n",
      "391\n",
      "390\n",
      "389\n",
      "388\n",
      "387\n",
      "386\n",
      "385\n",
      "384\n",
      "383\n",
      "382\n",
      "381\n",
      "380\n",
      "379\n",
      "378\n",
      "377\n",
      "376\n",
      "375\n",
      "374\n",
      "373\n",
      "372\n",
      "371\n",
      "370\n",
      "369\n",
      "368\n",
      "367\n",
      "366\n",
      "365\n",
      "364\n",
      "363\n",
      "362\n",
      "361\n",
      "360\n",
      "359\n",
      "358\n",
      "357\n",
      "356\n",
      "355\n",
      "354\n",
      "353\n",
      "352\n",
      "351\n",
      "350\n",
      "349\n",
      "348\n",
      "347\n",
      "346\n",
      "345\n",
      "344\n",
      "343\n",
      "342\n",
      "341\n",
      "340\n",
      "339\n",
      "338\n",
      "337\n",
      "336\n",
      "335\n",
      "334\n",
      "333\n",
      "332\n",
      "331\n",
      "330\n",
      "329\n",
      "328\n",
      "327\n",
      "326\n",
      "325\n",
      "324\n",
      "323\n",
      "322\n",
      "321\n",
      "320\n",
      "319\n",
      "318\n",
      "317\n",
      "316\n",
      "315\n",
      "314\n",
      "313\n",
      "312\n",
      "311\n",
      "310\n",
      "309\n",
      "308\n",
      "307\n",
      "306\n",
      "305\n",
      "304\n",
      "303\n",
      "302\n",
      "301\n",
      "300\n",
      "299\n",
      "298\n",
      "297\n",
      "296\n",
      "295\n",
      "294\n",
      "293\n",
      "292\n",
      "291\n",
      "290\n",
      "289\n",
      "288\n",
      "287\n",
      "286\n",
      "285\n",
      "284\n",
      "283\n",
      "282\n",
      "281\n",
      "280\n",
      "279\n",
      "278\n",
      "277\n",
      "276\n",
      "275\n",
      "274\n",
      "273\n",
      "272\n",
      "271\n",
      "270\n",
      "269\n",
      "268\n",
      "267\n",
      "266\n",
      "265\n",
      "264\n",
      "263\n",
      "262\n",
      "261\n",
      "260\n",
      "259\n",
      "258\n",
      "257\n",
      "256\n",
      "255\n",
      "254\n",
      "253\n",
      "252\n",
      "251\n",
      "250\n",
      "249\n",
      "248\n",
      "247\n",
      "246\n",
      "245\n",
      "244\n",
      "243\n",
      "242\n",
      "241\n",
      "240\n",
      "239\n",
      "238\n",
      "237\n",
      "236\n",
      "235\n",
      "234\n",
      "233\n",
      "232\n",
      "231\n",
      "230\n",
      "229\n",
      "228\n",
      "227\n",
      "226\n",
      "225\n",
      "224\n",
      "223\n",
      "222\n",
      "221\n",
      "220\n",
      "219\n",
      "218\n",
      "217\n",
      "216\n",
      "215\n",
      "214\n",
      "213\n",
      "212\n",
      "211\n",
      "210\n",
      "209\n",
      "208\n",
      "207\n",
      "206\n",
      "205\n",
      "204\n",
      "203\n",
      "202\n",
      "201\n",
      "200\n",
      "199\n",
      "198\n",
      "197\n",
      "196\n",
      "195\n",
      "194\n",
      "193\n",
      "192\n",
      "191\n",
      "190\n",
      "189\n",
      "188\n",
      "187\n",
      "186\n",
      "185\n",
      "184\n",
      "183\n",
      "182\n",
      "181\n",
      "180\n",
      "179\n",
      "178\n",
      "177\n",
      "176\n",
      "175\n",
      "174\n",
      "173\n",
      "172\n",
      "171\n",
      "170\n",
      "169\n",
      "168\n",
      "167\n",
      "166\n",
      "165\n",
      "164\n",
      "163\n",
      "162\n",
      "161\n",
      "160\n",
      "159\n",
      "158\n",
      "157\n",
      "156\n",
      "155\n",
      "154\n",
      "153\n",
      "152\n",
      "151\n",
      "150\n",
      "149\n",
      "148\n",
      "147\n",
      "146\n",
      "145\n",
      "144\n",
      "143\n",
      "142\n",
      "141\n",
      "140\n",
      "139\n",
      "138\n",
      "137\n",
      "136\n",
      "135\n",
      "134\n",
      "133\n",
      "132\n",
      "131\n",
      "130\n",
      "129\n",
      "128\n",
      "127\n",
      "126\n",
      "125\n",
      "124\n",
      "123\n",
      "122\n",
      "121\n",
      "120\n",
      "119\n",
      "118\n",
      "117\n",
      "116\n",
      "115\n",
      "114\n",
      "113\n",
      "112\n",
      "111\n",
      "110\n",
      "109\n",
      "108\n",
      "107\n",
      "106\n",
      "105\n",
      "104\n",
      "103\n",
      "102\n",
      "101\n",
      "100\n",
      "99\n",
      "98\n",
      "97\n",
      "96\n",
      "95\n",
      "94\n",
      "93\n",
      "92\n",
      "91\n",
      "90\n",
      "89\n",
      "88\n",
      "87\n",
      "86\n",
      "85\n",
      "84\n",
      "83\n",
      "82\n",
      "81\n",
      "80\n",
      "79\n",
      "78\n",
      "77\n",
      "76\n",
      "75\n",
      "74\n",
      "73\n",
      "72\n",
      "71\n",
      "70\n",
      "69\n",
      "68\n",
      "67\n",
      "66\n",
      "65\n",
      "64\n",
      "63\n",
      "62\n",
      "61\n",
      "60\n",
      "59\n",
      "58\n",
      "57\n",
      "56\n",
      "55\n",
      "54\n",
      "53\n",
      "52\n",
      "51\n",
      "50\n",
      "49\n",
      "48\n",
      "47\n",
      "46\n",
      "45\n",
      "44\n",
      "43\n",
      "42\n",
      "41\n",
      "40\n",
      "39\n",
      "38\n",
      "37\n",
      "36\n",
      "35\n",
      "34\n",
      "33\n",
      "32\n",
      "31\n",
      "30\n",
      "29\n",
      "28\n",
      "27\n",
      "26\n",
      "25\n",
      "24\n",
      "23\n",
      "22\n",
      "21\n",
      "20\n",
      "19\n",
      "18\n",
      "17\n",
      "16\n",
      "15\n",
      "14\n",
      "13\n",
      "12\n",
      "11\n",
      "10\n",
      "9\n",
      "8\n",
      "7\n",
      "6\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n",
      "19325\n"
     ]
    }
   ],
   "source": [
    "#This just writes all urls from the date range to a list hansardurls. Takes about 20 mins.\n",
    "#Some of this code has been adapted from: https://towardsdatascience.com/scraping-hansard-with-python-and-beautifulsoup-f2887f0bc937\n",
    "hansardurls = []\n",
    "for i in range(967,0,-1):\n",
    "    print(i)\n",
    "    url = 'https://hansard.parliament.uk/search/Debates?endDate=2019-11-29&house=Commons&startDate=2016-01-01&page={}&partial=true'.format(i)\n",
    "    rall = requests.get(url)\n",
    "    r = rall.content\n",
    "    soup = BeautifulSoup(r,\"lxml\")\n",
    "    titles = soup.find_all('a',class_=\"no-underline\")\n",
    "    for t in titles:\n",
    "        hurl = 'https://hansard.parliament.uk'+t['href']\n",
    "        hansardurls.append(hurl)\n",
    "print(len(hansardurls))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12-13\n"
     ]
    }
   ],
   "source": [
    "c = hansardurls[2344][38:48]\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-06-06\n"
     ]
    }
   ],
   "source": [
    "#I accidentally started at january 2016 before, so I used this to delete everything before 06-2016\n",
    "\n",
    "#del hansardurls[0]\n",
    "#print(hansardurls[0][38:48])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16980"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hansardurls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-06-06\n",
      "2016-06-09\n",
      "2016-06-15\n",
      "2016-06-29\n",
      "2016-07-05\n",
      "2016-07-11\n",
      "2016-07-14\n",
      "2016-07-20\n",
      "2016-09-06\n",
      "2016-09-12\n",
      "2016-09-15\n",
      "2016-10-12\n",
      "2016-10-18\n",
      "2016-10-20\n",
      "2016-10-26\n",
      "2016-10-31\n",
      "2016-11-03\n",
      "2016-11-14\n",
      "2016-11-17\n",
      "2016-11-22\n",
      "2016-11-28\n",
      "2016-12-01\n",
      "2016-12-07\n",
      "2016-12-12\n",
      "2016-12-15\n",
      "2017-01-09\n",
      "2017-01-12\n",
      "2017-01-18\n",
      "2017-01-24\n",
      "2017-01-26\n",
      "2017-02-01\n",
      "2017-02-07\n",
      "2017-02-09\n",
      "2017-02-22\n",
      "2017-02-27\n",
      "2017-03-02\n",
      "2017-03-07\n",
      "2017-03-13\n",
      "2017-03-16\n",
      "2017-03-21\n",
      "2017-03-24\n",
      "2017-03-29\n",
      "2017-04-19\n",
      "2017-04-24\n",
      "2017-04-27\n",
      "2017-06-28\n",
      "2017-07-05\n",
      "2017-07-11\n",
      "2017-07-18\n",
      "2017-09-05\n",
      "2017-09-11\n",
      "2017-09-14\n",
      "2017-10-11\n",
      "2017-10-17\n",
      "2017-10-23\n",
      "2017-10-26\n",
      "2017-11-01\n",
      "2017-11-06\n",
      "2017-11-14\n",
      "2017-11-20\n",
      "2017-11-23\n",
      "2017-11-29\n",
      "2017-12-04\n",
      "2017-12-07\n",
      "2017-12-13\n",
      "2017-12-19\n",
      "2017-12-21\n",
      "2018-01-11\n",
      "2018-01-16\n",
      "2018-01-22\n",
      "2018-01-25\n",
      "2018-01-30\n",
      "2018-02-02\n",
      "2018-02-07\n",
      "2018-02-20\n",
      "2018-02-26\n",
      "2018-02-28\n",
      "2018-03-06\n",
      "2018-03-12\n",
      "2018-03-15\n",
      "2018-03-20\n",
      "2018-03-26\n",
      "2018-03-28\n",
      "2018-04-17\n",
      "2018-04-23\n",
      "2018-04-25\n",
      "2018-04-30\n",
      "2018-05-03\n",
      "2018-05-10\n",
      "2018-05-15\n",
      "2018-05-21\n",
      "2018-05-23\n",
      "2018-06-05\n",
      "2018-06-11\n",
      "2018-06-14\n",
      "2018-06-19\n",
      "2018-06-25\n",
      "2018-06-27\n",
      "2018-07-03\n",
      "2018-07-05\n",
      "2018-07-10\n",
      "2018-07-12\n",
      "2018-07-18\n",
      "2018-07-23\n",
      "2018-09-04\n",
      "2018-09-10\n",
      "2018-09-13\n",
      "2018-10-11\n",
      "2018-10-17\n",
      "2018-10-23\n",
      "2018-10-25\n",
      "2018-10-31\n",
      "2018-11-05\n",
      "2018-11-13\n",
      "2018-11-15\n",
      "2018-11-21\n",
      "2018-11-26\n",
      "2018-11-29\n",
      "2018-12-05\n",
      "2018-12-11\n",
      "2018-12-13\n",
      "2018-12-19\n",
      "2019-01-07\n",
      "2019-01-10\n",
      "2019-01-16\n",
      "2019-01-21\n",
      "2019-01-24\n",
      "2019-01-29\n",
      "2019-02-04\n",
      "2019-02-07\n",
      "2019-02-12\n",
      "2019-02-14\n",
      "2019-02-20\n",
      "2019-02-25\n",
      "2019-02-27\n",
      "2019-03-05\n",
      "2019-03-07\n",
      "2019-03-12\n",
      "2019-03-18\n",
      "2019-03-20\n",
      "2019-03-25\n",
      "2019-03-28\n",
      "2019-04-02\n",
      "2019-04-08\n",
      "2019-04-11\n",
      "2019-04-25\n",
      "2019-05-01\n",
      "2019-05-08\n",
      "2019-05-13\n",
      "2019-05-16\n",
      "2019-05-22\n",
      "2019-06-05\n",
      "2019-06-10\n",
      "2019-06-13\n",
      "2019-06-19\n",
      "2019-06-25\n",
      "2019-06-27\n",
      "2019-07-03\n",
      "2019-07-09\n",
      "2019-07-15\n",
      "2019-07-18\n",
      "2019-07-24\n",
      "2019-09-03\n",
      "2019-09-09\n",
      "2019-10-02\n",
      "2019-10-07\n",
      "2019-10-17\n",
      "2019-10-23\n",
      "2019-10-29\n",
      "2019-10-31\n"
     ]
    }
   ],
   "source": [
    "#This makes a dict with keys being the dates of parliament proceedings and the values being a list of all the urls\n",
    "#of proceedings that happened on that date.\n",
    "dict_of_urls = defaultdict(list)\n",
    "for i in range(0,len(hansardurls)):\n",
    "    b = hansardurls[i][38:48]\n",
    "    dict_of_urls[str(b)].append(hansardurls[i])\n",
    "    if i % 100 == 0:\n",
    "        print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Early attempt at turning the text from the html file to a string, doesn't look good\n",
    "\n",
    "url = dict_of_urls['2016-06-06'][0]\n",
    "res = requests.get(url)\n",
    "html_page = res.content\n",
    "soup = BeautifulSoup(html_page, 'html.parser')\n",
    "text = soup.find_all(text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Made two functions to better turn the html file to text. Works better but there's still some unnecessary stuff in there\n",
    "\n",
    "from bs4.element import Comment\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "def tag_visible(element):\n",
    "    if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]']:\n",
    "        return False\n",
    "    if isinstance(element, Comment):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def text_from_html(body):\n",
    "    soup = BeautifulSoup(body, 'html.parser')\n",
    "    texts = soup.findAll(text=True)\n",
    "    visible_texts = filter(tag_visible, texts)  \n",
    "    return u\" \".join(t.strip() for t in visible_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Cookies: We use cookies to give you the best possible experience on our site. By continuing to use the site you\r\n",
      "            agree to our use of cookies. Find out more   OK       UK Parliament   Parliamentary Business  MPs, Lords and Offices  About Parliament  Get Involved  Visit  Education           Toggle navigation  Menu     Hansard    Hansard        Commons   Latest Sitting  Browse Sittings   Find Debates  Find Divisions   Find MPs     Lords   Latest Sitting  Browse Sittings   Find Debates  Find Divisions   Find Peers     About   Hansard Online                Previous  Top  Next            House of Commons Hansard      x              Contents      Commons Chamber      Oral Answers to Questions      Communities and Local Government      Text only        Back to Contents                      Previous    Edinburgh and South East Scotland City  Regional Deal     Next          Share       06 June 2016   Volume 611          The edit just sent has not been saved.  The following error was returned:     This content has already been edited and is awaiting review.     Deidre Brock (Edinburgh North and Leith) (SNP)       Share       7.  What progress has been made on the Edinburgh and south-east Scotland city regional deal. [905269]     Share          The edit just sent has not been saved.  The following error was returned:     This content has already been edited and is awaiting review.     The Parliamentary Under-Secretary of State for Communities and Local Government (James Wharton)       Share       Discussions continue positively on a city deal for Edinburgh and south-east Scotland. Officials have had a number of meetings and progress is being made, and Members across the House hope that an agreement can be reached so that something can be delivered that will benefit the hon. Lady’s constituents and our economy as a whole.     Share          The edit just sent has not been saved.  The following error was returned:     This content has already been edited and is awaiting review.     Deidre Brock       Share       I have heard that one local authority involved in the Edinburgh city region deal, West Lothian Council, has distanced itself from the development of the deal and now appears to be intending to step away altogether. How will the Minister encourage it back into the ring on that deal?     Share          The edit just sent has not been saved.  The following error was returned:     This content has already been edited and is awaiting review.     James Wharton       Share       The processes are by agreement, but we hope that all local authorities look to see the positives in what can be delivered, and the difference that can be made to the local economy, when city deals are agreed. My noble Friend the Under-Secretary at the Scotland Office will meet the leaders of Scottish cities on 8 June. I will draw his attention to the hon. Lady’s comments in the hope that he can bear them in mind and perhaps overcome some of the obstacles.     Share          The edit just sent has not been saved.  The following error was returned:     This content has already been edited and is awaiting review.     Peter Kyle (Hove) (Lab)       Share       rose—     Share          The edit just sent has not been saved.  The following error was returned:     This content has already been edited and is awaiting review.     Mr Speaker       Share       Order. Edinburgh and south-east Scotland are a very long way from Hove. Notwithstanding the hon. Gentleman’s considerable ingenuity, I find it hard to see how he can relate this to Hove. He should be patient and have another go on another question. Keep waiting, man, and keep in good spirits. We will get you in somehow.     Share                   ×   Suggest Correction            Your Details:         Enter your suggested correction:   0 /1000          Please prove you are not a robot.        Close  Submit               A-Z index | Glossary | Contact us | Freedom of Information | Data Protection |  Jobs | Using this website |  Copyright     © Parliamentary Copyright          \n"
     ]
    }
   ],
   "source": [
    "a = str(text_from_html(requests.get(url).content))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mentions of Brexit-Related Words Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from datetime import datetime\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debates per month "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first viewed how often a debate takes place to get an idea of when to expect more frequent appearences of words. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/Users/caoimherosemartin/Desktop/dates.txt'\n",
    "dates = list()\n",
    "with open(dataset_path, encoding=\"utf8\") as textfile:\n",
    "    reader = textfile.read()\n",
    "    #next(reader) # skips header line\n",
    "    for item in reader.split(','):\n",
    "        x = re.findall(r\"\\d*-\\d*-\\d*\", item)\n",
    "        dates.append(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getyear(x):\n",
    "    \"\"\"passes in a string with date, returns year\"\"\"\n",
    "    #convert it to datetime type\n",
    "    a = datetime.strptime(x, '%Y-%m-%d')\n",
    "    #take month from this \n",
    "    year = a.year\n",
    "    return year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates16 = [date for date in dates if getyear(date)==2016]\n",
    "dates17 = [date for date in dates if getyear(date)==2017]\n",
    "dates18 = [date for date in dates if getyear(date)==2018]\n",
    "dates19 = [date for date in dates if getyear(date)==2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getmonth(x):\n",
    "    \"\"\"passes in a string with date, returns month\"\"\"\n",
    "    #convert it to datetime type\n",
    "    a = datetime.strptime(x, '%Y-%m-%d')\n",
    "    #take month from this \n",
    "    month = a.month\n",
    "    return month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2016 \n",
    "l16 = []\n",
    "\n",
    "for date in dates16:\n",
    "    mon = getmonth(date)\n",
    "    l16.append(mon)\n",
    "\n",
    "\n",
    "freqs16 = {num:l16.count(num) for num in range(1,13)}\n",
    "# none in august \n",
    "#freqs16[8]=0\n",
    "#need to sort by key \n",
    "\n",
    "ord_freqs16 = collections.OrderedDict(sorted(freqs16.items(), key=lambda t: t[0]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#2017 \n",
    "l17 = []\n",
    "\n",
    "for date in dates17:\n",
    "    mon = getmonth(date)\n",
    "    l17.append(mon)\n",
    "\n",
    "\n",
    "freqs17 = {num:l17.count(num) for num in range(1,13)}\n",
    "#freqs17[8]=0\n",
    "#need to sort by key \n",
    "\n",
    "ord_freqs17 = collections.OrderedDict(sorted(freqs17.items(), key=lambda t: t[0]))\n",
    "\n",
    "\n",
    "#2018 \n",
    "l18 = []\n",
    "\n",
    "for date in dates18:\n",
    "    mon = getmonth(date)\n",
    "    l18.append(mon)\n",
    "\n",
    "\n",
    "freqs18 = {num:l18.count(num) for num in range(1,13)}\n",
    "# none in august \n",
    "#freqs18[8]=0\n",
    "#need to sort by key \n",
    "\n",
    "ord_freqs18 = collections.OrderedDict(sorted(freqs18.items(), key=lambda t: t[0]))\n",
    "\n",
    "\n",
    "#2019 \n",
    "l19 = []\n",
    "\n",
    "for date in dates19:\n",
    "    mon = getmonth(date)\n",
    "    l19.append(mon)\n",
    "\n",
    "\n",
    "freqs19 = {num:l19.count(num) for num in range(1,13)}\n",
    "#freqs19[8]=0\n",
    "#need to sort by key \n",
    "\n",
    "ord_freqs19 = collections.OrderedDict(sorted(freqs19.items(), key=lambda t: t[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2016\n",
    "x16 = np.arange(12)\n",
    "y16 = [val for key,val in ord_freqs16.items()]\n",
    "months16 = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "plt.title('Number of days with debates per month in the House of Commons: 2016')\n",
    "plt.bar(x16,y16, color = 'red')\n",
    "plt.xticks(x16, months16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2017 \n",
    "x17 = np.arange(12)\n",
    "y17 = [val for key,val in ord_freqs17.items()]\n",
    "months17 = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "plt.title('Number of days with debates per month in the House of Commons: 2017')\n",
    "plt.bar(x17,y17, color = 'red')\n",
    "plt.xticks(x17, months17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2018\n",
    "x18 = np.arange(12)\n",
    "y18 = [val for key,val in ord_freqs18.items()]\n",
    "months18 = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "plt.title('Number of days with debates per month in the House of Commons: 2018')\n",
    "plt.bar(x18,y18, color = 'red')\n",
    "plt.xticks(x18, months18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2019 \n",
    "x19 = np.arange(12)\n",
    "y19 = [val for key,val in ord_freqs19.items()]\n",
    "months19 = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "plt.title('Number of days with debates per month in the House of Commons: 2019')\n",
    "plt.bar(x19,y19, color = 'red')\n",
    "plt.xticks(x19, months19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 5 Selected Brexit Buzzwords (total occurences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering and retreiving data from each file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each transcript starts and ends with a segment of text regarding cookies, privacy etc. We first remove thif from the file, also removing the occurrences of the word \"Share\" if it is surrounded by multiple spaces, as this indicates it is a share button, and not text to be taken into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing on one file \n",
    "\n",
    "def getdata(file):\n",
    "    with open(file, encoding=\"utf8\") as textfile:\n",
    "        reader = textfile.read()\n",
    "        #filtering out headings, ending, and share button \n",
    "        file_without_head = reader[867:-354] #start 867\n",
    "        f = file_without_head.replace(\" Share  \", '')\n",
    "        wordcount = Counter(f.split())\n",
    "        total_count = sum(wordcount.values())\n",
    "        brexit = wordcount[\"Brexit\"]\n",
    "        anpr = wordcount[\"ANPR\"]\n",
    "        eea = wordcount[\"EEA\"]\n",
    "        cta = wordcount[\"CTA\"]\n",
    "        sch = wordcount[\"Schengen\"]\n",
    "        nodeal = wordcount[\"no-deal\"]\n",
    "        add_to_count = brexit + anpr + eea + cta + sch + nodeal\n",
    "        return add_to_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "months_dict16 = {'1': 0, '2': 0, '3': 0, '4':0, '5':0, '6':0, '7':0, '8':0, '9':0, '10':0, '11':0, '12':0}\n",
    "months_dict17 = {'1': 0, '2': 0, '3': 0, '4':0, '5':0, '6':0, '7':0, '8':0, '9':0, '10':0, '11':0, '12':0}\n",
    "months_dict18 = {'1': 0, '2': 0, '3': 0, '4':0, '5':0, '6':0, '7':0, '8':0, '9':0, '10':0, '11':0, '12':0}\n",
    "months_dict19 = {'1': 0, '2': 0, '3': 0, '4':0, '5':0, '6':0, '7':0, '8':0, '9':0, '10':0, '11':0, '12':0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group each file per month and extract occurences of the words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir('/Users/caoimherosemartin/Desktop/project/TMCI-Project-Nov-2019/mentions/Dates'):\n",
    "    if filename[:4] == '2016': \n",
    "        month = filename[5:7]\n",
    "        if month[0]=='0':\n",
    "            month = month[1]\n",
    "        count = months_dict16[month]\n",
    "        words = getdata(filename)\n",
    "        newcount = count + words \n",
    "        months_dict16[month] = newcount\n",
    "    if filename[:4] == '2017': \n",
    "        month = filename[5:7]\n",
    "        if month[0]=='0':\n",
    "            month = month[1]\n",
    "        count = months_dict17[month]\n",
    "        words = getdata(filename)\n",
    "        newcount = count + words \n",
    "        months_dict17[month] = newcount\n",
    "    if filename[:4] == '2018': \n",
    "        month = filename[5:7]\n",
    "        if month[0]=='0':\n",
    "            month = month[1]\n",
    "        count = months_dict18[month]\n",
    "        words = getdata(filename)\n",
    "        newcount = count + words \n",
    "        months_dict18[month] = newcount\n",
    "    if filename[:4] == '2019': \n",
    "        month = filename[5:7]\n",
    "        if month[0]=='0':\n",
    "            month = month[1]\n",
    "        count = months_dict19[month]\n",
    "        words = getdata(filename)\n",
    "        newcount = count + words \n",
    "        months_dict19[month] = newcount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(months_dict16)\n",
    "print(months_dict17)\n",
    "print(months_dict18)\n",
    "print(months_dict19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allx16 = np.arange(12)\n",
    "ally16 = [val for key,val in months_dict16.items()]\n",
    "months16 = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "plt.ylim(0, 5000)\n",
    "\n",
    "plt.title('Mention Frequencies (all words): 2016')\n",
    "plt.plot(allx16,ally16, color = 'red', linestyle = '--')\n",
    "plt.scatter(allx16, ally16, color=\"blue\")\n",
    "plt.xticks(allx16, months16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allx17 = np.arange(12)\n",
    "ally17 = [val for key,val in months_dict17.items()]\n",
    "months17 = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "plt.ylim(0, 5000)\n",
    "plt.title('Mention Frequencies (all words): 2017')\n",
    "plt.plot(allx17,ally17, color = 'red', linestyle = '--')\n",
    "plt.scatter(allx17, ally17, color=\"blue\")\n",
    "plt.xticks(allx17, months17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allx18 = np.arange(12)\n",
    "ally18 = [val for key,val in months_dict18.items()]\n",
    "months18 = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "plt.ylim(0, 5000)\n",
    "plt.title('Mention Frequencies (all words): 2018')\n",
    "plt.plot(allx18,ally18, color = 'red', linestyle = '--')\n",
    "plt.scatter(allx18, ally18, color=\"blue\")\n",
    "plt.xticks(allx18, months18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allx19 = np.arange(12)\n",
    "ally19 = [val for key,val in months_dict19.items()]\n",
    "months19 = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "plt.ylim(0, 5000)\n",
    "plt.title('Mention Frequencies (all words): 2019')\n",
    "plt.plot(allx19,ally19, color = 'red', linestyle = '--')\n",
    "plt.scatter(allx19, ally19, color=\"blue\")\n",
    "plt.xticks(allx19, months19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Word Occurences "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'Brexit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdata_brexit(file):\n",
    "    with open(file, encoding=\"utf8\") as textfile:\n",
    "        reader = textfile.read()\n",
    "        #filtering out headings, ending, and share button \n",
    "        file_without_head = reader[867:-354] #start 867\n",
    "        f = file_without_head.replace(\" Share  \", '')\n",
    "        wordcount = Counter(f.split())\n",
    "        total_count = sum(wordcount.values())\n",
    "        brexit = wordcount[\"Brexit\"]\n",
    "        return brexit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brexit_months_dict16 = {'1': 0, '2': 0, '3': 0, '4':0, '5':0, '6':0, '7':0, '8':0, '9':0, '10':0, '11':0, '12':0}\n",
    "brexit_months_dict17 = {'1': 0, '2': 0, '3': 0, '4':0, '5':0, '6':0, '7':0, '8':0, '9':0, '10':0, '11':0, '12':0}\n",
    "brexit_months_dict18 = {'1': 0, '2': 0, '3': 0, '4':0, '5':0, '6':0, '7':0, '8':0, '9':0, '10':0, '11':0, '12':0}\n",
    "brexit_months_dict19 = {'1': 0, '2': 0, '3': 0, '4':0, '5':0, '6':0, '7':0, '8':0, '9':0, '10':0, '11':0, '12':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouping all files per month \n",
    "for filename in os.listdir('/Users/caoimherosemartin/Desktop/project/TMCI-Project-Nov-2019/mentions/Dates'):\n",
    "    if filename[:4] == '2016': \n",
    "        month = filename[5:7]\n",
    "        if month[0]=='0':\n",
    "            month = month[1]\n",
    "        count = brexit_months_dict16[month]\n",
    "        words = getdata_brexit(filename)\n",
    "        newcount = count + words \n",
    "        brexit_months_dict16[month] = newcount\n",
    "    if filename[:4] == '2017': \n",
    "        month = filename[5:7]\n",
    "        if month[0]=='0':\n",
    "            month = month[1]\n",
    "        count = brexit_months_dict17[month]\n",
    "        words = getdata_brexit(filename)\n",
    "        newcount = count + words \n",
    "        brexit_months_dict17[month] = newcount\n",
    "    if filename[:4] == '2018': \n",
    "        month = filename[5:7]\n",
    "        if month[0]=='0':\n",
    "            month = month[1]\n",
    "        count = brexit_months_dict18[month]\n",
    "        words = getdata_brexit(filename)\n",
    "        newcount = count + words \n",
    "        brexit_months_dict18[month] = newcount\n",
    "    if filename[:4] == '2019': \n",
    "        month = filename[5:7]\n",
    "        if month[0]=='0':\n",
    "            month = month[1]\n",
    "        count = brexit_months_dict19[month]\n",
    "        words = getdata_brexit(filename)\n",
    "        newcount = count + words \n",
    "        brexit_months_dict19[month] = newcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(brexit_months_dict16)\n",
    "print(brexit_months_dict17)\n",
    "print(brexit_months_dict18)\n",
    "print(brexit_months_dict19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bx16 = np.arange(12)\n",
    "by16 = [val for key,val in brexit_months_dict16.items()]\n",
    "b_months16 = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "plt.ylim(0, 3000)\n",
    "plt.title('Mention Frequencies (Brexit): 2016')\n",
    "plt.plot(bx16,by16, color = 'red', linestyle = '--')\n",
    "plt.scatter(bx16, by16, color=\"blue\")\n",
    "plt.xticks(bx16, b_months16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bx17 = np.arange(12)\n",
    "by17 = [val for key,val in brexit_months_dict17.items()]\n",
    "b_months17 = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "plt.ylim(0, 3000)\n",
    "plt.title('Mention Frequencies (Brexit): 2017')\n",
    "plt.plot(bx17,by17, color = 'red', linestyle = '--')\n",
    "plt.scatter(bx17, by17, color=\"blue\")\n",
    "plt.xticks(bx17, b_months17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bx18 = np.arange(12)\n",
    "by18 = [val for key,val in brexit_months_dict18.items()]\n",
    "b_months18 = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "plt.ylim(0, 3000)\n",
    "plt.title('Mention Frequencies (Brexit): 2018')\n",
    "plt.plot(bx18,by18, color = 'red', linestyle = '--')\n",
    "plt.scatter(bx18, by18, color=\"blue\")\n",
    "plt.xticks(bx18, b_months18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bx19 = np.arange(12)\n",
    "by19 = [val for key,val in brexit_months_dict19.items()]\n",
    "b_months19 = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "plt.ylim(0, 3000)\n",
    "plt.title('Mention Frequencies (Brexit): 2019')\n",
    "plt.plot(bx19,by19, color = 'red', linestyle = '--')\n",
    "plt.scatter(bx19, by19, color=\"blue\")\n",
    "plt.xticks(bx19, b_months19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'ANPR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdata_anpr(file):\n",
    "    with open(file, encoding=\"utf8\") as textfile:\n",
    "        reader = textfile.read()\n",
    "        #filtering out headings, ending, and share button \n",
    "        file_without_head = reader[867:-354] #start 867\n",
    "        f = file_without_head.replace(\" Share  \", '')\n",
    "        wordcount = Counter(f.split())\n",
    "        total_count = sum(wordcount.values())\n",
    "        anpr = wordcount[\"ANPR\"]\n",
    "        return anpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anpr_months_dict16 = {'1': 0, '2': 0, '3': 0, '4':0, '5':0, '6':0, '7':0, '8':0, '9':0, '10':0, '11':0, '12':0}\n",
    "anpr_months_dict17 = {'1': 0, '2': 0, '3': 0, '4':0, '5':0, '6':0, '7':0, '8':0, '9':0, '10':0, '11':0, '12':0}\n",
    "anpr_months_dict18 = {'1': 0, '2': 0, '3': 0, '4':0, '5':0, '6':0, '7':0, '8':0, '9':0, '10':0, '11':0, '12':0}\n",
    "anpr_months_dict19 = {'1': 0, '2': 0, '3': 0, '4':0, '5':0, '6':0, '7':0, '8':0, '9':0, '10':0, '11':0, '12':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouping all files per month \n",
    "for filename in os.listdir('/Users/caoimherosemartin/Desktop/project/TMCI-Project-Nov-2019/mentions/Dates'):\n",
    "    if filename[:4] == '2016': \n",
    "        month = filename[5:7]\n",
    "        if month[0]=='0':\n",
    "            month = month[1]\n",
    "        count = anpr_months_dict16[month]\n",
    "        words = getdata_anpr(filename)\n",
    "        newcount = count + words \n",
    "        anpr_months_dict16[month] = newcount\n",
    "    if filename[:4] == '2017': \n",
    "        month = filename[5:7]\n",
    "        if month[0]=='0':\n",
    "            month = month[1]\n",
    "        count = anpr_months_dict17[month]\n",
    "        words = getdata_anpr(filename)\n",
    "        newcount = count + words \n",
    "        anpr_months_dict17[month] = newcount\n",
    "    if filename[:4] == '2018': \n",
    "        month = filename[5:7]\n",
    "        if month[0]=='0':\n",
    "            month = month[1]\n",
    "        count = anpr_months_dict18[month]\n",
    "        words = getdata_anpr(filename)\n",
    "        newcount = count + words \n",
    "        anpr_months_dict18[month] = newcount\n",
    "    if filename[:4] == '2019': \n",
    "        month = filename[5:7]\n",
    "        if month[0]=='0':\n",
    "            month = month[1]\n",
    "        count = anpr_months_dict19[month]\n",
    "        words = getdata_anpr(filename)\n",
    "        newcount = count + words \n",
    "        anpr_months_dict19[month] = newcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(anpr_months_dict16)\n",
    "print(anpr_months_dict17)\n",
    "print(anpr_months_dict18)\n",
    "print(anpr_months_dict19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anprx18 = np.arange(12)\n",
    "anpry18 = [val for key,val in anpr_months_dict18.items()]\n",
    "anpr_months18 = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "plt.ylim(0, 20)\n",
    "plt.title('Mention Frequencies (ANPR): 2018')\n",
    "plt.plot(anprx18,anpry18, color = 'red', linestyle = '--')\n",
    "plt.scatter(anprx18, anpry18, color=\"blue\")\n",
    "plt.xticks(anprx18, anpr_months18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anprx19 = np.arange(12)\n",
    "anpry19 = [val for key,val in anpr_months_dict19.items()]\n",
    "anpr_months19 = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "plt.ylim(0, 20)\n",
    "plt.title('Mention Frequencies (ANPR): 2019')\n",
    "plt.plot(anprx19,anpry19, color = 'red', linestyle = '--')\n",
    "plt.scatter(anprx19, anpry19, color=\"blue\")\n",
    "plt.xticks(anprx19, anpr_months19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'EEA' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdata_eea(file):\n",
    "    with open(file, encoding=\"utf8\") as textfile:\n",
    "        reader = textfile.read()\n",
    "        #filtering out headings, ending, and share button \n",
    "        file_without_head = reader[867:-354] #start 867\n",
    "        f = file_without_head.replace(\" Share  \", '')\n",
    "        wordcount = Counter(f.split())\n",
    "        total_count = sum(wordcount.values())\n",
    "        eea = wordcount[\"EEA\"]\n",
    "        return eea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eea_months_dict16 = {'1': 0, '2': 0, '3': 0, '4':0, '5':0, '6':0, '7':0, '8':0, '9':0, '10':0, '11':0, '12':0}\n",
    "eea_months_dict17 = {'1': 0, '2': 0, '3': 0, '4':0, '5':0, '6':0, '7':0, '8':0, '9':0, '10':0, '11':0, '12':0}\n",
    "eea_months_dict18 = {'1': 0, '2': 0, '3': 0, '4':0, '5':0, '6':0, '7':0, '8':0, '9':0, '10':0, '11':0, '12':0}\n",
    "eea_months_dict19 = {'1': 0, '2': 0, '3': 0, '4':0, '5':0, '6':0, '7':0, '8':0, '9':0, '10':0, '11':0, '12':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouping all files per month \n",
    "for filename in os.listdir('/Users/caoimherosemartin/Desktop/project/TMCI-Project-Nov-2019/mentions/Dates'):\n",
    "    if filename[:4] == '2016': \n",
    "        month = filename[5:7]\n",
    "        if month[0]=='0':\n",
    "            month = month[1]\n",
    "        count = eea_months_dict16[month]\n",
    "        words = getdata_eea(filename)\n",
    "        newcount = count + words \n",
    "        eea_months_dict16[month] = newcount\n",
    "    if filename[:4] == '2017': \n",
    "        month = filename[5:7]\n",
    "        if month[0]=='0':\n",
    "            month = month[1]\n",
    "        count = eea_months_dict17[month]\n",
    "        words = getdata_eea(filename)\n",
    "        newcount = count + words \n",
    "        eea_months_dict17[month] = newcount\n",
    "    if filename[:4] == '2018': \n",
    "        month = filename[5:7]\n",
    "        if month[0]=='0':\n",
    "            month = month[1]\n",
    "        count = eea_months_dict18[month]\n",
    "        words = getdata_eea(filename)\n",
    "        newcount = count + words \n",
    "        eea_months_dict18[month] = newcount\n",
    "    if filename[:4] == '2019': \n",
    "        month = filename[5:7]\n",
    "        if month[0]=='0':\n",
    "            month = month[1]\n",
    "        count = eea_months_dict19[month]\n",
    "        words = getdata_eea(filename)\n",
    "        newcount = count + words \n",
    "        eea_months_dict19[month] = newcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eea_months_dict16)\n",
    "print(eea_months_dict17)\n",
    "print(eea_months_dict18)\n",
    "print(eea_months_dict19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeax16 = np.arange(12)\n",
    "eeay16 = [val for key,val in eea_months_dict16.items()]\n",
    "\n",
    "eea_months16 = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "plt.ylim(0, 800)\n",
    "plt.title('Mention Frequencies (EEA): 2016')\n",
    "plt.plot(eeax16,eeay16, color = 'red', linestyle = '--')\n",
    "plt.scatter(eeax16, eeay16, color=\"blue\")\n",
    "plt.xticks(eeax16, eea_months16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeax17 = np.arange(12)\n",
    "eeay17 = [val for key,val in eea_months_dict17.items()]\n",
    "\n",
    "eea_months17 = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "plt.ylim(0, 800)\n",
    "plt.title('Mention Frequencies (EEA): 2017')\n",
    "plt.plot(eeax17,eeay17, color = 'red', linestyle = '--')\n",
    "plt.scatter(eeax17, eeay17, color=\"blue\")\n",
    "plt.xticks(eeax17, eea_months17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeax18 = np.arange(12)\n",
    "eeay18 = [val for key,val in eea_months_dict18.items()]\n",
    "\n",
    "eea_months18 = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "plt.ylim(0, 800)\n",
    "plt.title('Mention Frequencies (EEA): 2018')\n",
    "plt.plot(eeax18,eeay18, color = 'red', linestyle = '--')\n",
    "plt.scatter(eeax18, eeay18, color=\"blue\")\n",
    "plt.xticks(eeax18, eea_months18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeax19 = np.arange(12)\n",
    "eeay19 = [val for key,val in eea_months_dict19.items()]\n",
    "\n",
    "eea_months19 = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "plt.ylim(0, 800)\n",
    "plt.title('Mention Frequencies (EEA): 2019')\n",
    "plt.plot(eeax19,eeay19, color = 'red', linestyle = '--')\n",
    "plt.scatter(eeax19, eeay19, color=\"blue\")\n",
    "plt.xticks(eeax19, eea_months19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'CTA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdata_cta(file):\n",
    "    with open(file, encoding=\"utf8\") as textfile:\n",
    "        reader = textfile.read()\n",
    "        #filtering out headings, ending, and share button \n",
    "        file_without_head = reader[867:-354] #start 867\n",
    "        f = file_without_head.replace(\" Share  \", '')\n",
    "        wordcount = Counter(f.split())\n",
    "        total_count = sum(wordcount.values())\n",
    "        cta = wordcount[\"CTA\"]\n",
    "        return cta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cta_months_dict16 = {'1': 0, '2': 0, '3': 0, '4':0, '5':0, '6':0, '7':0, '8':0, '9':0, '10':0, '11':0, '12':0}\n",
    "cta_months_dict17 = {'1': 0, '2': 0, '3': 0, '4':0, '5':0, '6':0, '7':0, '8':0, '9':0, '10':0, '11':0, '12':0}\n",
    "cta_months_dict18 = {'1': 0, '2': 0, '3': 0, '4':0, '5':0, '6':0, '7':0, '8':0, '9':0, '10':0, '11':0, '12':0}\n",
    "cta_months_dict19 = {'1': 0, '2': 0, '3': 0, '4':0, '5':0, '6':0, '7':0, '8':0, '9':0, '10':0, '11':0, '12':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouping all files per month \n",
    "for filename in os.listdir('/Users/caoimherosemartin/Desktop/project/TMCI-Project-Nov-2019/mentions/Dates'):\n",
    "    if filename[:4] == '2016': \n",
    "        month = filename[5:7]\n",
    "        if month[0]=='0':\n",
    "            month = month[1]\n",
    "        count = cta_months_dict16[month]\n",
    "        words = getdata_cta(filename)\n",
    "        newcount = count + words \n",
    "        cta_months_dict16[month] = newcount\n",
    "    if filename[:4] == '2017': \n",
    "        month = filename[5:7]\n",
    "        if month[0]=='0':\n",
    "            month = month[1]\n",
    "        count = cta_months_dict17[month]\n",
    "        words = getdata_cta(filename)\n",
    "        newcount = count + words \n",
    "        cta_months_dict17[month] = newcount\n",
    "    if filename[:4] == '2018': \n",
    "        month = filename[5:7]\n",
    "        if month[0]=='0':\n",
    "            month = month[1]\n",
    "        count = cta_months_dict18[month]\n",
    "        words = getdata_cta(filename)\n",
    "        newcount = count + words \n",
    "        cta_months_dict18[month] = newcount\n",
    "    if filename[:4] == '2019': \n",
    "        month = filename[5:7]\n",
    "        if month[0]=='0':\n",
    "            month = month[1]\n",
    "        count = cta_months_dict19[month]\n",
    "        words = getdata_cta(filename)\n",
    "        newcount = count + words \n",
    "        cta_months_dict19[month] = newcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cta_months_dict16)\n",
    "print(cta_months_dict17)\n",
    "print(cta_months_dict18)\n",
    "print(cta_months_dict19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctax16 = np.arange(12)\n",
    "ctay16 = [val for key,val in cta_months_dict16.items()]\n",
    "\n",
    "cta_months16 = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "plt.ylim(0, 100)\n",
    "plt.title('Mention Frequencies (CTA): 2016')\n",
    "plt.plot(ctax16,ctay16, color = 'red', linestyle = '--')\n",
    "plt.scatter(ctax16, ctay16, color=\"blue\")\n",
    "plt.xticks(ctax16, cta_months16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctax17 = np.arange(12)\n",
    "ctay17 = [val for key,val in cta_months_dict17.items()]\n",
    "\n",
    "cta_months17 = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "plt.ylim(0, 100)\n",
    "plt.title('Mention Frequencies (CTA): 2017')\n",
    "plt.plot(ctax17,ctay17, color = 'red', linestyle = '--')\n",
    "plt.scatter(ctax17, ctay17, color=\"blue\")\n",
    "plt.xticks(ctax17, cta_months17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctax18 = np.arange(12)\n",
    "ctay18 = [val for key,val in cta_months_dict18.items()]\n",
    "\n",
    "cta_months18 = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "plt.ylim(0, 100)\n",
    "plt.title('Mention Frequencies (CTA): 2018')\n",
    "plt.plot(ctax18,ctay18, color = 'red', linestyle = '--')\n",
    "plt.scatter(ctax18, ctay18, color=\"blue\")\n",
    "plt.xticks(ctax18, cta_months18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctax19 = np.arange(12)\n",
    "ctay19 = [val for key,val in cta_months_dict19.items()]\n",
    "\n",
    "cta_months19 = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "plt.ylim(0, 100)\n",
    "plt.title('Mention Frequencies (CTA): 2016')\n",
    "plt.plot(ctax19,ctay19, color = 'red', linestyle = '--')\n",
    "plt.scatter(ctax19, ctay19, color=\"blue\")\n",
    "plt.xticks(ctax19, cta_months19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'Schengen'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdata_sch(file):\n",
    "    with open(file, encoding=\"utf8\") as textfile:\n",
    "        reader = textfile.read()\n",
    "        #filtering out headings, ending, and share button \n",
    "        file_without_head = reader[867:-354] #start 867\n",
    "        f = file_without_head.replace(\" Share  \", '')\n",
    "        wordcount = Counter(f.split())\n",
    "        total_count = sum(wordcount.values())\n",
    "        sch = wordcount[\"Schengen\"]\n",
    "        return sch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sch_months_dict16 = {'1': 0, '2': 0, '3': 0, '4':0, '5':0, '6':0, '7':0, '8':0, '9':0, '10':0, '11':0, '12':0}\n",
    "sch_months_dict17 = {'1': 0, '2': 0, '3': 0, '4':0, '5':0, '6':0, '7':0, '8':0, '9':0, '10':0, '11':0, '12':0}\n",
    "sch_months_dict18 = {'1': 0, '2': 0, '3': 0, '4':0, '5':0, '6':0, '7':0, '8':0, '9':0, '10':0, '11':0, '12':0}\n",
    "sch_months_dict19 = {'1': 0, '2': 0, '3': 0, '4':0, '5':0, '6':0, '7':0, '8':0, '9':0, '10':0, '11':0, '12':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir('/Users/caoimherosemartin/Desktop/project/TMCI-Project-Nov-2019/mentions/Dates'):\n",
    "    if filename[:4] == '2016': \n",
    "        month = filename[5:7]\n",
    "        if month[0]=='0':\n",
    "            month = month[1]\n",
    "        count = sch_months_dict16[month]\n",
    "        words = getdata_sch(filename)\n",
    "        newcount = count + words \n",
    "        sch_months_dict16[month] = newcount\n",
    "    if filename[:4] == '2017': \n",
    "        month = filename[5:7]\n",
    "        if month[0]=='0':\n",
    "            month = month[1]\n",
    "        count = sch_months_dict17[month]\n",
    "        words = getdata_sch(filename)\n",
    "        newcount = count + words \n",
    "        sch_months_dict17[month] = newcount\n",
    "    if filename[:4] == '2018': \n",
    "        month = filename[5:7]\n",
    "        if month[0]=='0':\n",
    "            month = month[1]\n",
    "        count = sch_months_dict18[month]\n",
    "        words = getdata_sch(filename)\n",
    "        newcount = count + words \n",
    "        sch_months_dict18[month] = newcount\n",
    "    if filename[:4] == '2019': \n",
    "        month = filename[5:7]\n",
    "        if month[0]=='0':\n",
    "            month = month[1]\n",
    "        count = sch_months_dict19[month]\n",
    "        words = getdata_sch(filename)\n",
    "        newcount = count + words \n",
    "        sch_months_dict19[month] = newcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sch_months_dict16)\n",
    "print(sch_months_dict17)\n",
    "print(sch_months_dict18)\n",
    "print(sch_months_dict19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schx16 = np.arange(12)\n",
    "schy16 = [val for key,val in sch_months_dict16.items()]\n",
    "\n",
    "sch_months16 = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "plt.ylim(0, 80)\n",
    "plt.title('Mention Frequencies (Schengen): 2016')\n",
    "plt.plot(schx16,schy16, color = 'red', linestyle = '--')\n",
    "plt.scatter(schx16, schy16, color=\"blue\")\n",
    "plt.xticks(schx16, sch_months16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schx17 = np.arange(12)\n",
    "schy17 = [val for key,val in sch_months_dict17.items()]\n",
    "\n",
    "sch_months17 = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "plt.ylim(0, 80)\n",
    "plt.title('Mention Frequencies (Schengen): 2017')\n",
    "plt.plot(schx17,schy17, color = 'red', linestyle = '--')\n",
    "plt.scatter(schx17, schy17, color=\"blue\")\n",
    "plt.xticks(schx17, sch_months17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schx18 = np.arange(12)\n",
    "schy18 = [val for key,val in sch_months_dict18.items()]\n",
    "\n",
    "sch_months18 = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "plt.ylim(0, 80)\n",
    "plt.title('Mention Frequencies (Schengen): 2018')\n",
    "plt.plot(schx18,schy18, color = 'red', linestyle = '--')\n",
    "plt.scatter(schx18, schy18, color=\"blue\")\n",
    "plt.xticks(schx18, sch_months18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schx19 = np.arange(12)\n",
    "schy19 = [val for key,val in sch_months_dict19.items()]\n",
    "\n",
    "sch_months19 = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "plt.ylim(0, 80)\n",
    "plt.title('Mention Frequencies (Schengen): 2019')\n",
    "plt.plot(schx19,schy19, color = 'red', linestyle = '--')\n",
    "plt.scatter(schx19, schy19, color=\"blue\")\n",
    "plt.xticks(schx19, sch_months19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'no-deal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdata_nd(file):\n",
    "    with open(file, encoding=\"utf8\") as textfile:\n",
    "        reader = textfile.read()\n",
    "        #filtering out headings, ending, and share button \n",
    "        file_without_head = reader[867:-354] #start 867\n",
    "        f = file_without_head.replace(\" Share  \", '')\n",
    "        wordcount = Counter(f.split())\n",
    "        total_count = sum(wordcount.values())\n",
    "        nd = wordcount[\"no-deal\"]\n",
    "        return nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd_months_dict16 = {'1': 0, '2': 0, '3': 0, '4':0, '5':0, '6':0, '7':0, '8':0, '9':0, '10':0, '11':0, '12':0}\n",
    "nd_months_dict17 = {'1': 0, '2': 0, '3': 0, '4':0, '5':0, '6':0, '7':0, '8':0, '9':0, '10':0, '11':0, '12':0}\n",
    "nd_months_dict18 = {'1': 0, '2': 0, '3': 0, '4':0, '5':0, '6':0, '7':0, '8':0, '9':0, '10':0, '11':0, '12':0}\n",
    "nd_months_dict19 = {'1': 0, '2': 0, '3': 0, '4':0, '5':0, '6':0, '7':0, '8':0, '9':0, '10':0, '11':0, '12':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir('/Users/caoimherosemartin/Desktop/project/TMCI-Project-Nov-2019/mentions/Dates'):\n",
    "    if filename[:4] == '2016': \n",
    "        month = filename[5:7]\n",
    "        if month[0]=='0':\n",
    "            month = month[1]\n",
    "        count = nd_months_dict16[month]\n",
    "        words = getdata_nd(filename)\n",
    "        newcount = count + words \n",
    "        nd_months_dict16[month] = newcount\n",
    "    if filename[:4] == '2017': \n",
    "        month = filename[5:7]\n",
    "        if month[0]=='0':\n",
    "            month = month[1]\n",
    "        count = nd_months_dict17[month]\n",
    "        words = getdata_nd(filename)\n",
    "        newcount = count + words \n",
    "        nd_months_dict17[month] = newcount\n",
    "    if filename[:4] == '2018': \n",
    "        month = filename[5:7]\n",
    "        if month[0]=='0':\n",
    "            month = month[1]\n",
    "        count = nd_months_dict18[month]\n",
    "        words = getdata_nd(filename)\n",
    "        newcount = count + words \n",
    "        nd_months_dict18[month] = newcount\n",
    "    if filename[:4] == '2019': \n",
    "        month = filename[5:7]\n",
    "        if month[0]=='0':\n",
    "            month = month[1]\n",
    "        count = nd_months_dict19[month]\n",
    "        words = getdata_nd(filename)\n",
    "        newcount = count + words \n",
    "        nd_months_dict19[month] = newcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nd_months_dict16)\n",
    "print(nd_months_dict17)\n",
    "print(nd_months_dict18)\n",
    "print(nd_months_dict19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndx17 = np.arange(12)\n",
    "ndy17 = [val for key,val in nd_months_dict17.items()]\n",
    "\n",
    "nd_months17 = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "plt.ylim(0, 1750)\n",
    "plt.title('Mention Frequencies (no-deal): 2017')\n",
    "plt.plot(ndx17,ndy17, color = 'red', linestyle = '--')\n",
    "plt.scatter(ndx17, ndy17, color=\"blue\")\n",
    "plt.xticks(ndx17, nd_months17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndx18 = np.arange(12)\n",
    "ndy18 = [val for key,val in nd_months_dict18.items()]\n",
    "\n",
    "nd_months18 = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "plt.ylim(0, 1750)\n",
    "plt.title('Mention Frequencies (no-deal): 2018')\n",
    "plt.plot(ndx18,ndy18, color = 'red', linestyle = '--')\n",
    "plt.scatter(ndx18, ndy18, color=\"blue\")\n",
    "plt.xticks(ndx18, nd_months18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndx19 = np.arange(12)\n",
    "ndy19 = [val for key,val in nd_months_dict19.items()]\n",
    "\n",
    "nd_months19 = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "plt.ylim(0, 1750)\n",
    "plt.title('Mention Frequencies (no-deal): 2019')\n",
    "plt.plot(ndx19,ndy19, color = 'red', linestyle = '--')\n",
    "plt.scatter(ndx19, ndy19, color=\"blue\")\n",
    "plt.xticks(ndx19, nd_months19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context of Brexit-related words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = open(\"Dates/dates.txt\", \"r\", encoding=\"UTF-8\") \n",
    "x = list(fh)[0].split(\",\")\n",
    "dates=[y[2:-1] for y in x]\n",
    "print(dates[0], dates[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "from collections import Counter\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for date in dates:\n",
    "    path=\"Dates/\"+date\n",
    "    f = open(path, \"r\", encoding=\"UTF-8\") \n",
    "print(', '.join(f)[-100:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the text used for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampletxt=\".     Angela Smith (Penistone and Stocksbridge) (Lab)       Share       It is a pleasure to follow the hon. Member for Eastleigh (Mims Davies). I echo many of the comments about the economy made by my hon. Friends on the Front Bench, particularly in relation to productivity, with the latest figures showing the largest quarterly fall since 2008. I acknowledge that the Government have issued a challenge to areas such as mine to play their part in tackling the productivity and economic growth gap by developing devolution in the form of the northern powerhouse. I for one accept that challenge. I accept that Sheffield city region has to raise its game. We have to play our part and believe in ourselves, which we have not done for a very long time. Quite simply—as one employer said to me today in an email—we must believe that we have the skills, knowledge and ability to surpass London and become a generator of great wealth again. However, the Government must play their part too, and at the moment they are not doing so. The announcement today about the Department for Business, Innovation and Skills and the relocation of staff from Sheffield to London belies everything that the Government have said on this point, but they can remedy the situation. I will be watching carefully the development of the infrastructure plan. In particular, I will be looking for confirmation that the new trans-Pennine links between Manchester and Sheffield will be given the green light, as they are essential to the future of the northern economy. I will keep up the pressure on the Government to support a positive outcome to the steel crisis. Funnily enough, the crisis in South Yorkshire has triggered a revival in the faith and the confidence that we used to have in ourselves and in our engineering prowess. My plea to the Government today is: please do not let us down. We believe that we are the best steel producers in the world. If the Government believe in us, we will deliver. Let me turn now to the biggest threat facing the economy in the next few years—the instability that is currently characterising our political system. Let us be clear about this: in the UK, politics is polarising. We know that it is happening on the Labour Benches, as we have shifted to the left. On the Government Benches, Brexit is tearing the Conservative party apart, and the centre ground is disappearing before our very eyes. What on earth happened to the politics of the art of the possible? This movement is happening globally. In some countries, the polarisation is even greater. One has to look only at Austria last week and at Holland, where the three mainstream parties are set to secure, in total, just 40% in the elections next year. As we have seen, even the US is not immune from the phenomenon. Globalisation is one of the main causes of the situation. I echo the words of Mr Blair who said today that the problem of the centre ground was that it looks “as if we are managers of the status quo and not changers of it”. It is a worrying trend, and polarisation of the political sphere is creating a vacuum that could visit lasting damage on the social and economic fabric of this country. We bear a responsibility to resurrect the relevance of pragmatic politics. We need to demonstrate that centre-ground politics can deliver a progressive, prosperous and secure future for the people of this country. If we do not do that, the future of this country and its economy is very much in danger.     Share           2.43 pm        The edit just \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampletxt[:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a function to save all sentences of a file in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "s=set(stopwords.words('english'))\n",
    "\n",
    "#added missing stopwords\n",
    "extrastopwords=[\"would\", \"could\", \"us\", \"share\"]\n",
    "for w in extrastopwords:\n",
    "    s.add(w)\n",
    "\n",
    "print(len(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savesent(text):\n",
    "    #input: text\n",
    "    #output: list of sentences of filtered text\n",
    "    lst = []\n",
    "    #creating list with all words by seperation by spaces. except for words that are \"\" and stopwords\n",
    "    lot = [i for i in list(text.split(\" \")) if i != \"\"]\n",
    "    lot = [i for i in lot if i.lower() not in s]\n",
    "    #starting the sentence\n",
    "    sent=\"\"\n",
    "    for i in lot:\n",
    "        i=nltk.WordNetLemmatizer().lemmatize(i.lower())\n",
    "        #all indicate an end to a sentence so all words that are not an end of sentence (eos)\n",
    "        if i[-1] not in (\".\", \"!\", \"?\"):\n",
    "            if i[-1]in (\",\", \"-\", \"—\"):\n",
    "                i=nltk.WordNetLemmatizer().lemmatize(i[:-1])\n",
    "            sent+=i #adds the word without the eos indication\n",
    "            sent+=\" \"\n",
    "        #else it is an end of sentence and the sentence get appended to the lst of sentences\n",
    "        else:\n",
    "            sent+=nltk.WordNetLemmatizer().lemmatize(i[:-1])\n",
    "            lst.append(sent)\n",
    "            sent=\"\"\n",
    "    #returns list of sentences\n",
    "    return lst\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"Dates/2016-05-26\", \"r\", encoding=\"UTF-8\") \n",
    "file=', '.join(f)\n",
    "sentences = savesent(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences[200:210]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savesent(\"what? yes! hello Prime minister. hoping walked yes cats cats.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#words we want to focus on\n",
    "words = [\"brexit\", \"anpr\", \"cta\", \"eea\", \"schengen\"]\n",
    "\n",
    "spansize = 5\n",
    "\n",
    "cooccsw1 = Counter()\n",
    "cooccsw2 = Counter()\n",
    "cooccsw3 = Counter()\n",
    "cooccsw4 = Counter()\n",
    "cooccsw5 = Counter()\n",
    "\n",
    "def allcooccs(text, date=True):\n",
    "    sentences = savesent(text)\n",
    "    for sentence in sentences:\n",
    "        lowords = sentence.split(\" \")\n",
    "        for i in range(0, len(lowords)):\n",
    "            w=lowords[i].lower()\n",
    "            if w in (\" \",\"%\", \"`\",\"~\",\"…\", '£', \"”\", '×', '—', 'ç', '“', '’', '/', '©', \"\\n\", \"[\", \"]\", '|', '‘'):\n",
    "                continue\n",
    "            for x in  (\".\", \"!\", \"?\"):\n",
    "                if x in w:\n",
    "                    j=w.find(x)\n",
    "                    l=len(w)\n",
    "                    w=w[:j-l]\n",
    "                    \n",
    "            if w in words:\n",
    "                span_range = list(range(max(i-spansize, 0), i))\n",
    "                \n",
    "                span_range.extend(range(i+1, min(i + spansize + 1, len(lowords))))\n",
    "                \n",
    "                try:\n",
    "                    for cw in [lowords[idx] for idx in span_range if len(lowords[idx])>2]:\n",
    "                        if w == words[0]:\n",
    "                            cooccsw1[(w, cw)] += 1\n",
    "                        if w == words[1]:\n",
    "                            cooccsw2[(w, cw)] += 1\n",
    "                        if w == words[2]:\n",
    "                            cooccsw3[(w, cw)] += 1\n",
    "                        if w == words[3]:\n",
    "                            cooccsw4[(w, cw)] += 1\n",
    "                        if w == words[4]:\n",
    "                            cooccsw5[(w, cw)] += 1\n",
    "                except IndexError:\n",
    "                    print(\"word\", w, \"span\", span_range, date)\n",
    "                    \n",
    "    return cooccsw1,cooccsw2,cooccsw3,cooccsw4,cooccsw5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counting coocurances for all files for all centre words\n",
    "for date in dates:\n",
    "    path=\"Dates/\"+date\n",
    "    f = open(path, \"r\", encoding=\"UTF-8\") \n",
    "    file = (', '.join(f))\n",
    "    allcooccs(file, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cooccsw1.most_common(10)\n",
    "cooccsw2.most_common(10)\n",
    "cooccsw3.most_common(10)\n",
    "cooccsw4.most_common(10)\n",
    "cooccsw5.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#puts the top 10 cooccuring words as values to the centre words\n",
    "d={}\n",
    "\n",
    "d[words[0]]=[x[0][1] for x in cooccsw1.most_common(10)]\n",
    "d[words[1]]=[x[0][1] for x in cooccsw2.most_common(10)]\n",
    "d[words[2]]=[x[0][1] for x in cooccsw3.most_common(10)]\n",
    "d[words[3]]=[x[0][1] for x in cooccsw4.most_common(10)]\n",
    "d[words[4]]=[x[0][1] for x in cooccsw5.most_common(10)]\n",
    "\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(words[0], d[words[0]][0])\n",
    "print(cooccsw1[(words[0], d[words[0]][0])])\n",
    "\"no-deal\" in d[\"brexit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstw1=[cooccsw1[(words[0], x)] for x in d[words[0]]]\n",
    "lstw2=[cooccsw2[(words[1], x)] for x in d[words[1]]]\n",
    "lstw3=[cooccsw3[(words[2], x)] for x in d[words[2]]]\n",
    "lstw4=[cooccsw4[(words[3], x)] for x in d[words[3]]]\n",
    "lstw5=[cooccsw5[(words[4], x)] for x in d[words[4]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lstw1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "v1 = lstw1#list values\n",
    "k1 = d[words[0]]#list keys\n",
    "\n",
    "v2 = lstw2#list values\n",
    "k2 = d[words[1]]#list keys\n",
    "\n",
    "v3 = lstw3#list values\n",
    "k3 = d[words[2]]#list keys\n",
    "\n",
    "v4 = lstw4#list values\n",
    "k4 = d[words[3]]#list keys\n",
    "\n",
    "v5 = lstw5#list values\n",
    "k5 = d[words[4]]#list keys\n",
    "        \n",
    "plt.bar(k1, v1)\n",
    "plt.title(words[0])\n",
    "plt.show()\n",
    "\n",
    "plt.bar(k2, v2)\n",
    "plt.title(words[1])\n",
    "plt.show()\n",
    "\n",
    "plt.bar(k3, v3)\n",
    "plt.title(words[2])\n",
    "plt.show()\n",
    "\n",
    "plt.bar(k4, v4)\n",
    "plt.title(words[3])\n",
    "plt.show()\n",
    "\n",
    "plt.bar(k5, v5)\n",
    "plt.title(words[4])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we plot co-occurances over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstofmonths(start, finish):\n",
    "    lst=[start]\n",
    "    i=start\n",
    "    while i != finish:\n",
    "        if i[1]==12:\n",
    "            i=[i[0]+1, 1]\n",
    "        else:\n",
    "            i=[i[0], i[1]+1]\n",
    "        lst.append(i)\n",
    "    return lst\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a list of the months and years\n",
    "months=lstofmonths([2016, 5],[2019, 11])\n",
    "print(months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check to see when elem in months and filename are the same\n",
    "x = [int(i) for i in \"2016-05-26\".split(\"-\")[:-1]]\n",
    "print(x, months[0])\n",
    "print(x==months[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cooccsv1(filetxt, words, d):\n",
    "    \n",
    "    #input: text, list of centrewords, dict with centre words as keys and list of top co-occuring words as value\n",
    "    #output: count of combination of centre word and co-occuring word\n",
    "    \n",
    "    sentences = savesent(filetxt)\n",
    "    for sentence in sentences:\n",
    "        lowords = sentence.split(\" \")\n",
    "        for i in range(0, len(lowords)):\n",
    "            w=lowords[i].lower()\n",
    "            for x in  (\".\", \"!\", \"?\"):\n",
    "                if x in w:\n",
    "                    j=w.find(x)\n",
    "                    l=len(w)\n",
    "                    w=w[:j-l]\n",
    "                    \n",
    "            if w in words:\n",
    "                span_range = list(range(max(i-spansize, 0), i))\n",
    "                \n",
    "                span_range.extend(range(i+1, min(i + spansize + 1, len(lowords))))\n",
    "                \n",
    "                for cw in [lowords[idx] for idx in span_range]:\n",
    "                    if cw in d[w]:\n",
    "                        cooccswm[(w, cw)] += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loallcooccs=[[[],[],[],[],[],[],[],[],[],[]],[[],[],[],[],[],[],[],[],[],[]],\n",
    "             [[],[],[],[],[],[],[],[],[],[]],[[],[],[],[],[],[],[],[],[],[]],\n",
    "             [[],[],[],[],[],[],[],[],[],[]]]\n",
    "\n",
    "\n",
    "for m in months:\n",
    "    #new counter each month\n",
    "    cooccswm = Counter()\n",
    "    #all possible dates of files\n",
    "    for date in dates:\n",
    "        \n",
    "        name = [int(i) for i in date.split(\"-\")[:-1]]\n",
    "        if m == name:\n",
    "            \n",
    "            path=\"Dates/\"+date\n",
    "            f = open(path, \"r\", encoding=\"UTF-8\") \n",
    "            filetxt = (', '.join(f))\n",
    "            cooccsv1(filetxt, words, d)\n",
    "            \n",
    "    for ww in range(0, 5):\n",
    "        word=words[ww]\n",
    "        for cww in range(0,10):\n",
    "            coword=d[word][cww]\n",
    "            value=cooccswm[(word, coword)]\n",
    "            loallcooccs[ww][cww].append(value)\n",
    "            \n",
    "print(loallcooccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test WHETHER THE COUNTER IS EQUAL TO SUM OF COUNTER PER MONTH\n",
    "len(loallcooccs[0][0])\n",
    "cooccsw1[(words[0], d[words[0]][0])] == sum(loallcooccs[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(w0cw0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "X = np.linspace(-6, 6, 1024)\n",
    "ranges=[800, 8, 50, 400, 50]\n",
    "\n",
    "months1h=[str(x) for x in months[:30]]\n",
    "months2h=[str(x) for x in months[30:]]\n",
    "\n",
    "for i in range(0, 5):\n",
    "    figure(num=None, figsize=(12, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "    plt.plot(months1h, loallcooccs[i][0][:30], marker='o', markerfacecolor='blue', markersize=12, color='skyblue', label=d[words[i]][0])\n",
    "    plt.plot(months1h, loallcooccs[i][1][:30], marker='', color='olive', linewidth=2, label=d[words[i]][1])\n",
    "    plt.plot(months1h, loallcooccs[i][2][:30], marker='', color='red', linewidth=2, linestyle='dashed', label=d[words[i]][2])\n",
    "    plt.plot(months1h, loallcooccs[i][3][:30], marker='', color='yellow', linewidth=2, label=d[words[0]][3])\n",
    "    plt.plot(months1h, loallcooccs[i][4][:30], marker='', color='orange', linewidth=2, linestyle='dashed', label=d[words[i]][4])\n",
    "    plt.plot(months1h, loallcooccs[i][5][:30], marker='o', markerfacecolor='darkblue', markersize=12, color='darkblue', label=d[words[i]][5])\n",
    "    plt.plot(months1h, loallcooccs[i][6][:30], marker='', color='salmon', linewidth=2, label=d[words[i]][6])\n",
    "    plt.plot(months1h, loallcooccs[i][7][:30], marker='', color='purple', linewidth=2, linestyle='dashed', label=d[words[i]][7])\n",
    "    plt.plot(months1h, loallcooccs[i][8][:30], marker='', color='skyblue', linewidth=2, label=d[words[i]][8])\n",
    "    plt.plot(months1h, loallcooccs[i][9][:30], marker='', color='green', linewidth=2, linestyle='dashed', label=d[words[i]][9])\n",
    "\n",
    "\n",
    "    plt.ylim(0, ranges[i])\n",
    "    plt.legend()\n",
    "    plt.title(words[i]+\" co-occurances 1st half\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    figure(num=None, figsize=(12, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "    months1h=[str(x) for x in months[:30]]\n",
    "    months2h=[str(x) for x in months[30:]]\n",
    "\n",
    "    plt.plot(months2h, loallcooccs[i][0][30:], marker='o', markerfacecolor='blue', markersize=12, color='skyblue', label=d[words[i]][0])\n",
    "    plt.plot(months2h, loallcooccs[i][1][30:], marker='', color='olive', linewidth=2, label=d[words[i]][1])\n",
    "    plt.plot(months2h, loallcooccs[i][2][30:], marker='', color='red', linewidth=2, linestyle='dashed', label=d[words[i]][2])\n",
    "    plt.plot(months2h, loallcooccs[i][3][30:], marker='', color='yellow', linewidth=2, label=d[words[0]][3])\n",
    "    plt.plot(months2h, loallcooccs[i][4][30:], marker='', color='orange', linewidth=2, linestyle='dashed', label=d[words[i]][4])\n",
    "    plt.plot(months2h, loallcooccs[i][5][30:], marker='o', markerfacecolor='darkblue', markersize=12, color='darkblue', label=d[words[i]][5])\n",
    "    plt.plot(months2h, loallcooccs[i][6][30:], marker='', color='salmon', linewidth=2, label=d[words[i]][6])\n",
    "    plt.plot(months2h, loallcooccs[i][7][30:], marker='', color='purple', linewidth=2, linestyle='dashed', label=d[words[i]][7])\n",
    "    plt.plot(months2h, loallcooccs[i][8][30:], marker='', color='skyblue', linewidth=2, label=d[words[i]][8])\n",
    "    plt.plot(months2h, loallcooccs[i][9][30:], marker='', color='green', linewidth=2, linestyle='dashed', label=d[words[i]][9])\n",
    "\n",
    "    plt.ylim(0, ranges[i])\n",
    "    plt.legend()\n",
    "    plt.title(words[i]+\" co-occurances 2nd half\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import sentiwordnet as swn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "word=list(swn.senti_synsets('luckily'))[0]\n",
    "word.pos_score()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "un2wn_mapping = {\"VERB\" : wn.VERB, \"NOUN\" : wn.NOUN, \"ADJ\" : wn.ADJ, \"ADV\" : wn.ADV}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentitext(text, pos, neg, obj):\n",
    "    #input: text and previous pos neg obj values\n",
    "    #output: new pos neg obj values based on the sentiments in all sentences\n",
    "    lst=savesent(text)\n",
    "    lstw=[]\n",
    "    print(\"savesent\")\n",
    "    for s in lst:\n",
    "        s = [w for w in s.split(\" \") if w.isalpha()]\n",
    "        for w, p in nltk.pos_tag(s, tagset=\"universal\"):\n",
    "            if len(w)>2:\n",
    "                if p in un2wn_mapping:\n",
    "                       lstw.append(w)\n",
    "    \n",
    "    print(\"pos-tagging\")\n",
    "    \n",
    "    for w in lstw:\n",
    "        try:\n",
    "            word=list(swn.senti_synsets(w))[0]\n",
    "            pos+=word.pos_score()\n",
    "            neg+=word.neg_score()\n",
    "            obj+=word.obj_score()\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        \n",
    "    return pos, neg, obj "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loallsenti=[[],[],[]]\n",
    "\n",
    "\n",
    "for m in months:\n",
    "    #to check how far the computation is\n",
    "    print(m)\n",
    "    #new counter each month\n",
    "    #all possible dates of files\n",
    "    pos=0\n",
    "    neg=0\n",
    "    obj=0\n",
    "    \n",
    "    for date in dates:\n",
    "        \n",
    "        name = [int(i) for i in date.split(\"-\")[:-1]]\n",
    "        if m == name:\n",
    "            \n",
    "            path=\"Dates/\"+date\n",
    "            f = open(path, \"r\", encoding=\"UTF-8\") \n",
    "            filetxt = (', '.join(f))\n",
    "            pos, neg, obj = sentitext(filetxt, pos, neg, obj)\n",
    "            \n",
    "    lstsenti =[pos, neg, obj]       \n",
    "    for i in range(0, 3):  \n",
    "        loallsenti[i].append(lstsenti[i])\n",
    "            \n",
    "    print(loallsenti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loallsenti=[[1207.528, 86470.19500000002, 93388.35699999999, 0, 70291.39300000011, 135537.99600000025, 142495.733, 96243.91000000003, 123605.273, 118817.64699999998, 150036.21200000035, 43347.26100000005, 0, 31694.868000000017, 85474.28000000007, 0, 53293.59800000006, 112331.681, 144889.9880000002, 104891.03199999993, 138800.37599999981, 104667.65699999995, 155335.56600000025, 74890.50600000002, 114910.73999999982, 138169.52400000018, 125643.92099999973, 0, 60627.95000000003, 121282.17699999998, 131979.13799999995, 109736.90300000003, 142345.09300000023, 147877.5080000002, 157904.3740000003, 93789.90799999995, 99167.277, 106594.39199999989, 121858.32599999984, 0, 45636.97300000006, 130353.65700000002, 7391.101999999997], [861.972, 56858.55499999986, 60903.392999999895, 0, 44997.98199999991, 88431.5039999999, 92923.2669999999, 64845.21499999984, 79013.1019999999, 78753.9779999999, 98958.66299999999, 28948.738999999958, 0, 20596.75699999999, 56584.09499999993, 0, 36336.02699999993, 76992.5689999999, 97806.51199999996, 70034.09299999989, 91517.49900000008, 70333.71799999998, 103877.55900000005, 50649.743999999904, 76595.01000000005, 94173.85099999982, 82655.57900000003, 0, 42167.92499999997, 80019.57299999984, 87595.86199999988, 76457.5969999999, 97885.53199999992, 98767.99200000001, 107166.37600000008, 65622.71699999989, 67138.97299999994, 70703.10799999998, 80933.799, 0, 32236.276999999955, 87783.84299999986, 4813.522999999999], [17172.5, 1228827.25, 1334871.25, 0, 977269.625, 1898890.5, 1981774.0, 1375369.875, 1736374.625, 1693286.375, 2131973.125, 630317.0, 0, 433832.375, 1207347.625, 0, 774949.375, 1584768.75, 2049456.5, 1502624.875, 1966292.125, 1492854.625, 2217527.875, 1055740.75, 1626102.25, 1972121.625, 1783714.5, 0, 878875.125, 1675922.25, 1877122.0, 1609959.5, 2049701.375, 2124102.5, 2267329.25, 1338140.375, 1370908.75, 1505431.5, 1670206.875, 0, 658127.75, 1815786.5, 103428.375]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "X = np.linspace(-6, 6, 1024)\n",
    "#ranges=[800, 8, 50, 400, 50]\n",
    "\n",
    "months1h=[str(x) for x in months[:30]]\n",
    "months2h=[str(x) for x in months[30:]]\n",
    "\n",
    "figure(num=None, figsize=(12, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.plot(months1h, loallsenti[0][:30], color='green', label=\"positive\")\n",
    "plt.plot(months1h, loallsenti[1][:30], color='red', label=\"negative\")\n",
    "\n",
    "\n",
    "#plt.ylim(0, ranges[i])\n",
    "plt.legend()\n",
    "plt.title(\" sentiments 1st half\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "figure(num=None, figsize=(12, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.plot(months2h, loallsenti[0][30:], color=\"green\", label=\"positive\")\n",
    "plt.plot(months2h, loallsenti[1][30:], color='red', label=\"negative\")\n",
    "   \n",
    "plt.legend()\n",
    "plt.title(\" sentiments 2nd half\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
